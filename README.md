# Хэш-таблица: исследование различных хэш-функций и возможностей оптимизации.

# Часть первая: хэш-функции.

## Описание работы

В первой части в учебных целях исследуются различные (в основном простейшие и неприменимые на практике) хэш-функции. 

Элементами хэш-таблицы являются пары "ключ-значение": ключом являются слово, состоящее из букв латинского алфавита или цифр, значением - количество раз, которое данное слово встретилось во входных данных. В качестве входных данных должен быть использован текстовый файл, в котором каждое слово находится на отдельной строке, без пробелов. Программа для каждой хэш-функции по очереди помещает слова из входных данных в хэш-таблицу, а затем создает в указанной папке файл с именем хэш-функции и записывает в него полученное распределение (длина цепочки в каждой ячейке хэш-таблицы).

## Подготовка входного файла

Для того чтобы превратить файл с неким текстом (например, `texts/miserables_vol1.txt`) во входной файл программы нужного формата, можно использовать скрипт на Python, запускаемый следующей командой из основной директории: 
```
python3 py_scripts/parse.py *входной файл* *имя выходного файла*
```

Пример:
```
python3 py_scripts/parse.py texts/miserables_vol1.txt texts/input.txt
```

Чтобы посчитать количество уникальных слов в файле (это может быть нужно для оценки размера хэш-таблицы), можно использовать другой скрипт, входным файлом для которого должен быть уже подготовленный файл (каждое слово на своей строке):
```
python3 py_scripts/uni_words.py *входной файл*
```

Пример:
```
python3 py_scripts/uni_words.py texts/input.txt
```


## Тестирование хэш-функций
1. Используйте команду `make`, чтобы скомпилировать программу.
2. В программе используются следующие аргументы командной строки:
    1. `--input` (`-i`) : входной файл
    2. `--output` (`-o`) : имя директории, в которой будет созданы файлы с результатами тестирования.
    3. `--table-size` (`-s`) : количество ячеек в хэш-таблице.
3. Запустите программу с нужными аргументами или самостоятельно, или с помощью команды `make run`. Пример: 
```
make run ARGS="-i texts/input.txt -o out -s 10271"
```

## Анализ результатов тестирования хэш-функций
Чтобы построить гистограмму распределения одной из хэш-функций, используйте скрипт:
```
python3 py_scripts/draw_hist.py *файл с результатами теста*
```

Пример:
```
python3 py_scripts/draw_hist.py out/hash_checksum
```

При запуске скрипта откроется интерактивное окно matplotlib. В заголовке гистограммы написаны название предоставленного файла и дисперсия (variance) данного распределения. Чем меньше значение дисперсии, тем равномернее распределение и выше скорость поиска в таблице (за счёт уменьшения средней длины цепочки).

### Полученные гистограммы:
- Входной файл для тестирования: `texts/input.txt`, полученный из `texts/miserables_vol1.txt`. 
- Размер хэш-таблицы: 10271 (простое число)

Код хэш-функций можно посмотреть в /src/hashfuncs.cpp.

![](/imgs/hash_funcs_hists/hash_const.png)
Функция возвращает всегда константное значение (19). Результат - единственная цепочка длиной в количество уникальных слов. Польза функции в том, что можно устроить проверку зрения (сможете увидеть столбик на гистограмме?)

![](/imgs/hash_funcs_hists/hash_first_letter_ascii.png)
Функция возвращает ascii-код первой буквы слова. Ожидаемо очень малый диапазон значений.

![](/imgs/hash_funcs_hists/hash_word_len.png)
Функция возвращает длину слова. Ожидаемо очень малый диапазон значений.

![](/imgs/hash_funcs_hists/hash_checksum.png)
Функция считает сумму ascii-кодов всех букв слова. Диапазон значений уже хотя бы достаточно широкий, чтобы он был виден на гистограмме, но все ещё довольно мал. Кроме того, внутри диапазона нет равномерности распределения.

![](/imgs/hash_funcs_hists/hash_rol_xor.png)
Функция итеративно использует ROL (битовый поворот влево) и XOR (исключающее или). Охвачен почти весь диапазон значений, дисперсия приблизилась к единице.

![](/imgs/hash_funcs_hists/hash_ror_xor.png)
Функция итеративно использует ROR (битовый поворот вправо) и XOR (исключающее или). **Результат отличается от предыдущей функции, несмотря на кажущееся малое различие, состоящее только в замене ROL на ROR. Охвачен меньший диапазон значений (больше пробелов), дисперсия около 5.** 

![](/imgs/hash_funcs_hists/hash_murmur3.png)
Используется известная хэш-функция murmur3. Дисперсия практически равна единице, визуально наблюдается равномерное распределение, а максимальный load factor равен 6.

# Часть вторая: оптимизации.

## Описание работы

Рассматривается следующая задача, использующая хэш-таблицу из первой части работы:
1. Хэш-таблица **один раз** заполняется известным набором входных данных (пары "слово" : "количество вхождений"). Входные данные состоят из известного заранее, не изменяющегося набора слов, которые могут повторять в каком-то порядке.
2. Производится **большое** количество запросов поиска в хэш-таблицу. Слова для поиска берутся из второго множества, про которое заранее известно, что максимальная длина слова не превышает максимальную длину слова из первого множества.

Требуется оптимизировать функцию поиска хэш-таблицы под данный сценарий работы.

### Компиляция программы для тестирования

Обычная команда `make` собирает в отладочном режиме, что не очень подходит для тестирования. Используется следующая команда:
```
make for_prof
```

Если требуется использовать флаг оптимизации компилятора, отличный от `-O3`, используйте команду вида (пример для `-O0`):
```
make for_prof OPTIMIZE=-O0
```

### Тестирование

Для запуска теста производительности поиска используется флаг `-t` с опциональным аргументом в виде имени файла, задающего множество слов для поиска. Данный файл должен быть подготовлен так же, как файл с входными данными (см. предыдущую часть). ВНИМАНИЕ: между именем файла и опцией НЕ должно быть пробела, например, `-tfile.txt`.

Стандартные настройки:
Input file: texts/input.txt
Search file: texts/search.txt
Hashtable's size: 10271 (подходит для texts/input.txt)

Команда для запуска тестирования со стандартными настройками:
```
make run ARGS="-t"
```

В конце тестирования выводится значение ("search perforamnce test dummy variable"), являющееся суммой всех результатов запросов и равное `732511132`. Данное число не должно меняться при использовании одной и той же пары множества входных слов и множества слов для поиска. ВАЖНО: это число рассчитывается заново для каждой итерации теста, а потому **не зависит** от количества итераций тестирования.
### Профилирование

Для определения узких мест в программе выбран профилировщик `perf` из `linux-tools`. (До этого были неудачные попытки использовать callgrind+kcachegrind и gprof, отнявшие значительное количество времени). Используются две основные команды:

- Компиляция и сбор данных профилирования при стандартных настройках:
```
make perf_record
```
Результаты записываются в файл `perf.data`.

- Отображение результатов:
- Таблица, позволяющая увидеть функции, имеющие наибольшее "собственное время":
```
make perf_report
```

### Просмотр ассемблерного листинга

В некоторых случаях может быть полезно изучить ассемблерный листинг файла некого исходного кода, полученный при тех же флагах компиляции, что и при компиляции для профилирования. Для этого используется следующая команда (на примере файла hashtable.cpp):

```
make make_asm FILE="src/hashtable.cpp"
```

Данная команда создаст ассемблерный листинг с названием `hashtable.s` в общей папке.

## Протокол профилирования и оптимизаций

### О методике и точности измерений коэффициента улучшение оптимизации

Для вычисления коэффициента, отражающего во сколько раз некоторая оптимизация ускорила работу программы в целом, применяется следующая методика:

1. Для уменьшения влияния сторонних факторов тестирование производится при единственной открытой программе (терминале) и установленной максимальной частоте процессора. (см. ниже про установку частоты). С помощью команды `make show_freq_policy` можно увидеть установленные на данный момент ограничения.

2. Выполняется команда `make for_prof`, чтобы скомпилировать программу для профилирования.

3. Выполняется команда (`time ./bin/prog -t`), которая возвращает оценочное количество секунд, затраченное на исполнение программы (пункт real).

4. Пункт `3.` выполняется ~15 раз подряд, из которых используются последние 10 полученных значений времён.

5. Полученные значения записываются в файл `time_tests/time_test_N`, где `N` - номер оптимизации, каждое на своей строчке.

6. С помощью скрипта вычисляется среднее значение, его абсолютная и относительная ошибка: `python3 py_scripts/abs_error.py time_tests/time_test_N`

7. Данное значение сравнивается с предыдущим и делается вывод об эффективности оптимизации.

**Установка максимальной частоты процессора**: Для этого применяется команда:
```
make set_max_freq MAX_FREQ=**частота в GHz**
```
Стандартное значение устанавливаемой частоты = 1.6GHz (применяется при опускании параметра MAX_FREQ).

### Начальное состояние

<!-- TODO - поменять сэмплы на замерянные времена!! -->
**Сэмплы**: 7056.5 ± 6.7, 0.09%

---

![](/imgs/perf_res_screenshots/0.png)

**Анализ**: Наиболее "тяжелой" является функция `__strcmp_avx2`, выполняющая роль strcmp при -O3. Просмотрев исходник, можно заметить, что отстуствие выравнивания слов приводит к затруднению при использовании SIMD инструкций.

**Гипотеза**: достичь лучшего результата получится, если помещать слова в блоки по 32 байта (слов длиннее 32 символов не встречается в данных), и использовать SIMD инструкции, работающие с выровненными блоками по 32 байта, для реализации strcmp.

### Первая оптимизация

**Сэмплы**: 6699 ± 33, 0.49%

**Эффективность**: ~5%. Просмотр листинга показывает, что сами инструкции, реализующие интринсики, довольно тяжелые: 

![](/imgs/perf_res_screenshots/1.1.png)

Но будем считать данную оптимизацию всё равно оправданной.

---

![](/imgs/perf_res_screenshots/1.png)

**Анализ**: Наиболее "тяжёлой" является функция `hashtable_find`. Самым горячим местом являются SIMD-инструкции, упомянутые выше, но следующим по горячести является инструкция divq, использующася для взятия остатка от деления хэша на размер хэш-таблицы (~700 сэмплов). Следующей по "тяжёлости" является функция хэширования, единственная возможная её оптимизация - замена на более быстродействующую. Затем идут 4 функции dedlist. Все они - однострочные, но компилятор не имеет права их встроить.

**Гипотеза**: Если захардкодить размер хэш-таблицы (это можно сделать, т.к. сценарий предполагает единственный набор входных данных), компилятор сможет соптимизировать взятие остатка от деления, заменив на набор более простых инструкций. Вынесение в хэдер с модификатором inline упомянутых функций dedlist поможет избежать задержек, вызванных инструкцией ret.